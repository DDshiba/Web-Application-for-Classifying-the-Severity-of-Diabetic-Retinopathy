import os
import tensorflow as tf
import cv2
import numpy as np
from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import io
import uvicorn
from functools import lru_cache
from tensorflow.keras.applications.efficientnet import preprocess_input

# ‚úÖ ‡∏õ‡∏¥‡∏î GPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ö‡∏ô Hugging Face
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
tf.config.set_visible_devices([], 'GPU')

# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á FastAPI App
app = FastAPI(
    title="DeepEye API",
    description="API for DR Classification",
    docs_url="/docs",
    redoc_url="/redoc",
)

print("‚úÖ API Started on Hugging Face Spaces!")

# ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ Debug ‡πÄ‡∏ä‡πá‡∏Å API ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î
@app.get("/debug-endpoints")
def debug_endpoints():
    return {"endpoints": [route.path for route in app.routes]}

# ‚úÖ API Health Check
@app.get("/")
def home():
    return {"message": "üî• FastAPI Backend is running on Hugging Face Spaces!"}

@app.get("/ping")
def ping():
    return {"status": "success", "message": "‚úÖ API is live!"}

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö Lazy Loading
model_path = os.path.join("EfficientNetB0_AdamW_freeze100__lr0_00001_1024512_tanh_RGB.keras")

@lru_cache()
def load_model():
    if os.path.exists(model_path):
        print(f"‚úÖ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: {model_path}")
        return tf.keras.models.load_model(model_path)
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: {model_path}")
    return None

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏±‡∏ö Contrast ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ CLAHE (RGB)
def apply_clahe_rgb(image):
    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    r, g, b = cv2.split(rgb_img)
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(12, 12))
    r_clahe = clahe.apply(r)
    g_clahe = clahe.apply(g)
    b_clahe = clahe.apply(b)
    return cv2.merge((r_clahe, g_clahe, b_clahe))

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏£‡∏µ‡πÇ‡∏û‡∏£‡πÄ‡∏ã‡∏™‡∏ã‡∏¥‡∏á‡∏†‡∏≤‡∏û
def preprocess_image(image):
    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)
    image = apply_clahe_rgb(image)
    image = image.astype("float32") / 255.0
    return np.expand_dims(preprocess_input(image * 255.0), axis=0)

# ‚úÖ ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á DR ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
CLASS_LABELS = {
    0: {"label": "0_No_DR", "description": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥", "level": 0},
    1: {"label": "1_Mild", "description": "‡∏†‡∏≤‡∏ß‡∏∞‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ï‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢", "level": 1},
    2: {"label": "2_Moderate", "description": "‡∏†‡∏≤‡∏ß‡∏∞‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ï‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", "level": 2},
    3: {"label": "3_Severe", "description": "‡∏†‡∏≤‡∏ß‡∏∞‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ï‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á", "level": 3},
    4: {"label": "4_Proliferative_DR", "description": "‡∏†‡∏≤‡∏ß‡∏∞‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ï‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏°‡∏≤‡∏Å", "level": 4},
}

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡πà‡∏≤ Softmax Output ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
def format_output(predictions, predicted_class):
    output_text = "\nüìä ‡∏Ñ‡πà‡∏≤‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:\n"
    for i, prob in enumerate(predictions[0]):  # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å batch
        output_text += f"‡∏Ñ‡∏•‡∏≤‡∏™ {i} ({CLASS_LABELS[i]['label']}) ‚Üí {prob:.6f} (‚âà {prob*100:.2f}%)"
        if i == predicted_class:
            output_text += " ‚úÖ (‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡∏ô‡∏µ‡πâ)"
        output_text += "\n"
    return output_text

# ‚úÖ API ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û
@app.post("/analyze")
async def analyze(file: UploadFile = File(...)):
    print("‚úÖ API /analyze ‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÅ‡∏•‡πâ‡∏ß!")  # ‚úÖ DEBUG LOG
    model = load_model()  # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î

    if model is None:
        return {"error": "‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á"}

    try:
        # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å Bytes
        img = Image.open(io.BytesIO(await file.read())).convert("RGB")
        img_cv = np.array(img)[:, :, ::-1]  # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á RGB ‚Üí BGR

        # ‚úÖ ‡∏û‡∏£‡∏µ‡πÇ‡∏û‡∏£‡πÄ‡∏ã‡∏™‡∏†‡∏≤‡∏û
        processed_img = preprocess_image(img_cv)

        # ‚úÖ ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
        predictions = model.predict(processed_img)
        predicted_class = int(np.argmax(predictions))  
        confidence = float(np.max(predictions))  
        predicted_info = CLASS_LABELS[predicted_class]

        print(format_output(predictions, predicted_class))  # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô format_output()
        
        return {
            "label": predicted_info["label"],
            "confidence": confidence,
            "description": predicted_info["description"],
            "level": predicted_info["level"]
        }

    except Exception as e:
        return {"error": str(e)}

# ‚úÖ ‡∏£‡∏±‡∏ô FastAPI ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Uvicorn
if __name__ == "__main__":
    print("üöÄ Starting Uvicorn Server...")
    uvicorn.run(app, host="0.0.0.0", port=7860, log_level="debug")