import os
import tensorflow as tf
import datetime
import cv2
import numpy as np
from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import io
from tensorflow.keras.applications.efficientnet import preprocess_input

# ‚úÖ ‡∏õ‡∏¥‡∏î GPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏ô CPU
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
tf.config.set_visible_devices([], 'GPU')

# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á FastAPI App
app = FastAPI()

# ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ CORS (‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏ó‡∏∏‡∏Å‡πÇ‡∏î‡πÄ‡∏°‡∏ô)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ Endpoint ‡πÄ‡∏ä‡πá‡∏Å‡∏ß‡πà‡∏≤ API ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
@app.get("/")
def home():
    return {"message": "üî• FastAPI Backend is running on Hugging Face Spaces!"}

# ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  
MODEL_PATH = os.path.join(BASE_DIR, "model", "EfficientNetB0_AdamW_freeze100__lr0_00001_1024512_tanh_RGB.keras")
UPLOAD_FOLDER = os.path.join(BASE_DIR, "uploads")  
PROCESSED_FOLDER = os.path.join(BASE_DIR, "processed")  
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(PROCESSED_FOLDER, exist_ok=True)

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ö‡∏ö Lazy Loading
model = None
def load_model():
    global model
    if model is None and os.path.exists(MODEL_PATH):
        print(f"‚úÖ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: {MODEL_PATH}")
        try:
            model = tf.keras.models.load_model(MODEL_PATH)
            print("‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        except Exception as e:
            print(f"‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏±‡∏ö Contrast ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ CLAHE (RGB)
def apply_clahe_rgb(image):
    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    r, g, b = cv2.split(rgb_img)
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(12, 12))
    r_clahe = clahe.apply(r)
    g_clahe = clahe.apply(g)
    b_clahe = clahe.apply(b)
    return cv2.merge((r_clahe, g_clahe, b_clahe))

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏£‡∏µ‡πÇ‡∏û‡∏£‡πÄ‡∏ã‡∏™‡∏ã‡∏¥‡∏á‡∏†‡∏≤‡∏û
def preprocess_image(image, save_path=None):
    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)
    image = apply_clahe_rgb(image)

    if save_path:
        cv2.imwrite(save_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))

    image = image.astype("float32") / 255.0
    image = preprocess_input(image * 255.0)
    return np.expand_dims(image, axis=0)

# ‚úÖ ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ç‡∏≠‡∏á DR ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
CLASS_LABELS = {
    0: {"label": "0_No_DR", "description": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥", "level": 0},
    1: {"label": "1_Mild", "description": "‡∏†‡∏≤‡∏ß‡∏∞‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ï‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢", "level": 1},
    2: {"label": "2_Moderate", "description": "‡∏†‡∏≤‡∏ß‡∏∞‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ï‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á", "level": 2},
    3: {"label": "3_Severe", "description": "‡∏†‡∏≤‡∏ß‡∏∞‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ï‡∏≤‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á", "level": 3},
    4: {"label": "4_Proliferative_DR", "description": "‡∏†‡∏≤‡∏ß‡∏∞‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ï‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏°‡∏≤‡∏Å", "level": 4},
}

# ‚úÖ API ‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å React ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏•‡∏±‡∏ö
@app.post("/analyze")
async def analyze(file: UploadFile = File(...)):
    load_model()  # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API

    if model is None:
        return {"error": "‚ùå ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á"}

    try:
        # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å Bytes
        img = Image.open(io.BytesIO(await file.read())).convert("RGB")
        img_cv = np.array(img)[:, :, ::-1]  # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á RGB ‚Üí BGR

        # ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        original_img_path = os.path.join(UPLOAD_FOLDER, f"uploaded_{timestamp}.png")
        img.save(original_img_path)

        # ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏ò‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô CLAHE
        processed_img_path = os.path.join(PROCESSED_FOLDER, f"processed_{timestamp}.png")

        # ‚úÖ ‡∏û‡∏£‡∏µ‡πÇ‡∏û‡∏£‡πÄ‡∏ã‡∏™‡∏†‡∏≤‡∏û ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        processed_img = preprocess_image(img_cv, save_path=processed_img_path)

        # ‚úÖ ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
        predictions = model.predict(processed_img)
        predicted_class = int(np.argmax(predictions))  
        confidence = float(np.max(predictions))  
        predicted_info = CLASS_LABELS[predicted_class]

        return {
            "label": predicted_info["label"],
            "confidence": confidence,
            "description": predicted_info["description"],
            "level": predicted_info["level"],
            "input_shape": str(processed_img.shape),
            "output_shape": str(predictions.shape),
            "original_size": img.size,
            "original_image": original_img_path,
            "processed_image": processed_img_path
        }

    except Exception as e:
        return {"error": str(e)}



# ‚úÖ ‡∏£‡∏±‡∏ô Backend
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 7860))  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏≠‡∏£‡πå‡∏ï 7860 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Hugging Face
    uvicorn.run("app:app", host="0.0.0.0", port=port, reload=True)

